#### Removing the tweets which are retweets.
        Tweets which are retweets have notnull values in the column of the retweeted_status_id. They are checked for by tweets_clean['retweeted_status_id'].value_counts().sum() which returned 181. Such tweets are checked for with this expression: tweets_clean = tweets_clean[~tweets_clean['retweeted_status_id'].notnull()]. Filtering for tweets which are original tweets by inversing the expression that obtains tweets which have not null values for retweeted_status_id. To ensure that rows that are retweets have been removed, printing tweets_clean['retweeted_status_id'].value_counts().sum() returned zero.
#### Removing columns: in_reply_to_status_id, in_reply_to_user_id, source, retweeted_status_id, retweeted_status_user_id and retweeted_status_timestamp.
        The columns: retweeted_status_id, retweeted_status_user_id and retweeted_status_timestamp are deemed obsolete since they are associated with tweets which are retweets which have been filtered off, hence dropping them was necessary. Columns: in_reply_to_status_id, in_reply_to_user_id, and source have most of the rows filled with NaN, therefore they are removed with the panda's function: drop and the new dataframe assigned into the variable: tweets_clean. Printing tweets_clean.columns shows they have been removed.
#### Newline character and url links in the column: text looks cubersome.
        Url links at the end of the column: text are expired. Also, the newline character '\n' in between the texts of the values of the column: text looks cubersome. They are checked for by printing a randon sample of the texts[['text']]. They are removed by applying a regular expression funtion: sub which replaces the newline character and urls with an empty string. It is checked by printing a 3 random of sample of the texts[['text]].
#### +0000 at the end of the values in the column: timestamp is repetitive.
      +0000 kept showing up repeatedly at the end of the values of the timestamp of the tweets_clean. It was removed through indexing and slicing. It was checking for by printing the top 3 rows of the dataframe.
#### Separating the values of the column: timestamp into 2 new columns: date and time.
        The values of the timestamp is separated into 2 parts: date and time with the pandas's function, split(). It was split at the whitespace and expanded into 2 new columns. The timestamp column was dropped subsequently. It was checked by printing out a list of the tweets__clean columns.
#### Datatype of the values in the column: date is object.
       The datatype of the values of the date in the tweets_clean is object which is inappropriate for values which is stating date. It was checked by calling info() on the tweets_clean. They are converted to the standard date format with the pandas's function: pd.to_datetime. Calling tweets_clean['date'].dtype returned M8[ns] which means datetime format.
#### Repeated links in the column: expanded urls.
      There were repeated urls in the columns: expanded urls of the tweets_clean separated by comma. Also, the datatype of values of the expanded urls is object. Before the repeated links can be removed, the datatype is converted to unicode which is also a string format in python 3 and readable. Hence, values with repeated links separated by comma are split by the comma and the first link in the list created is assigned to that row. It was tested by printign 3 random sample of tweets_cleans['expanded_urls'].
#### Some rows in the images prediction are not true for dogs.
      The predictions for images of dogs in the image predictions dataframe returned False which are filtered off by stating multiple conditons where the boolean value for the p1_dog, p2_dog and p3_dog returned False. A dataframe which returned True for the images of dogs was saved to dogs_true.
#### Combining the columns: Doggo, Floofer, Pupper and Puppo of the twitter-archive-enhanced into one column.
     The values of the columns: doggo, floofer, pupper and puppo are combined into one column named dog_stage by appending the forementioned columns with + operator. The columns: doggo, floofer, pupper and puppo were subsequently dropped. The dog_stage was checked with tweets_clean['dog_stages'].value_counts()
#### Merging tweet_json, image prediction and tweets-archive-enhanced tables as one.
     The copies of the image_prediction, tweets-archive-enchanced and counts tables obtained from the tweet_json are merge into one with merge function of pandas, joining them on tweet_id and saved into a file named twitter_archive_master.
